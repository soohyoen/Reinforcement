발산까지는 막았고, layer에 Input되는 통로의 값을 줄여보고 싶음 -> 학습속도가 빠르지 않을까..

Dense: 출력 뉴런의 수 60-> 40

현재 입력 뉴런은 39개 

→ 발산은 되지 않지만 학습이 진행이 되지 않음.. step 하나당 10000개가 넘어버림

→ 학습 결과는 좋음 하지만 val env로 검증 시 전혀 학습이 안된것 처럼 보임.
   과적합으로 예상되며, Dropout의 기법을 적용해봄
   Dropout을 적용해도 여전히 도리도리... 과적합의 문제가 아닌거같은데
  
    
